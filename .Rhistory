dim(M)
K <- 5
# ruvIIInb
ctl <- read.csv('/home/asalim/poisRUV/analysis/chen/scHK_human.csv', header=T)[,1]
out$logl;out2 <- ruvIIInb::ruvIII.nb(as.matrix(assays(sub)$counts),M=M,ctl=ctl,k=K,ncores=2,step.fac=0.1)
K <- 1
# ruvIIInb
ctl <- read.csv('/home/asalim/poisRUV/analysis/chen/scHK_human.csv', header=T)[,1]
out$logl;out2 <- ruvIIInb::ruvIII.nb(as.matrix(assays(sub)$counts),M=M,ctl=ctl,k=K,ncores=2,step.fac=0.5,batch=as.numeric(factor(sub$Individual)))
K <- 2
# ruvIIInb
ctl <- read.csv('/home/asalim/poisRUV/analysis/chen/scHK_human.csv', header=T)[,1]
out$logl;out2 <- ruvIIInb::ruvIII.nb(as.matrix(assays(sub)$counts),M=M,ctl=ctl,k=K,ncores=2,step.fac=0.5,batch=as.numeric(factor(sub$Individual)))
lfproc
edgeR::lfproc
nchar('Ganggu$$01')
x=rnorm(100)
y=rbinom(100,size=1,prob=0.5)
kruskal.test(x~y)
cluster::silhouette(y,dist(x))
z=rep(0,100)
cluster::silhouette(z,dist(x))
cluster::silhouette(z,dist(x))[,3]
Xvar=model.matrix(~y+z)
Xvar=model.matrix(~y+z)[,-1]
cancor(x=cbind(x,x^2),y=Xvar)
getwd()
?segments
x <- stats::runif(12); y <- stats::rnorm(12)
i <- order(x, y); x <- x[i]; y <- y[i]
plot(x, y, main = "arrows(.) and segments(.)")
## draw arrows from point to point :
s <- seq(length(x)-1)  # one shorter than data
arrows(x[s], y[s], x[s+1], y[s+1], col= 1:3)
s <- s[-length(s)]
segments(x[s], y[s], x[s+2], y[s+2], col= 'pink')
require(ruvIIInb)
vignette(package='ruvIIInb')
install_github("limfuxing/ruvIIInb,build_vignette=TRUE")
devtools::install_github("limfuxing/ruvIIInb,build_vignette=TRUE")
devtools::install_github("limfuxing/ruvIIInb",build_vignette=TRUE)
devtools::install_github("limfuxing/ruvIIInb",build_vignette=TRUE,force=TRUE)
require(ruvIIInb)
vignette(package='ruvIIInb')
?vignette
vignette("Introduction",package='ruvIIInb')
?ci.pred
ci.pred
require(ruvIIInb)
vignette('Introduction',package='ruvIIInb')
?scran::modelGeneVar
BiocManager::install('dino')
devtools::install_github("JBrownBiostat/Dino", build_vignettes = TRUE)
devtools::install_github('theislab/kBET')
require(ruvIIInb)
vignnette(pkgs='ruvIIInb')
vignette(pkgs='ruvIIInb')
vignette(package='ruvIIInb')
vignette('ruvIIInbVignette ',package='ruvIIInb')
vignette('ruvIIInbVignette',package='ruvIIInb')
require(ruvIIInb)
vignette('ruvIIInbVignette',package='ruvIIInb'
)
vignette('ruvIIInbVignette',package='ruvIIInb')
require(ruvIIInb)
require(edgeR)
design <- model.matrix(~stress*donor+pressure*donor+stress*pressure,contrasts=list(donor='contr.sum'),data=colData(sce))
y <- DGEList(counts=assays(sce)$counts,group=paste0(sce$stress,'-',sce$pressure))
y <- calcNormFactors(y)
y <- estimateDisp(y,design)
fit <- glmFit(y,design)
# prepare the contrast matrix
contr.mat <- matrix(0,nrow=9,ncol=ncol(design))
colnames(contr.mat) <- colnames(design)
# 30kpa vs 1000kpa in LSS
contr.mat[1,c("pressure30kpa","stressLSS:pressure30kpa")] <- 1
# 30kpa vs 1000kpa in HSS
contr.mat[2,c("pressure30kpa")] <- 1
# 200kpa vs 1000kpa in LSS
contr.mat[3,c("pressure200kpa","stressLSS:pressure200kpa")] <- 1
# 200kpa vs 1000kpa in HSS
contr.mat[4,c("pressure200kpa")] <- 1
# 200kpa vs 30kpa in LSS
contr.mat[5,c("pressure200kpa","stressLSS:pressure200kpa")] <- 1
contr.mat[5,c("pressure30kpa","stressLSS:pressure30kpa")]   <- -1
# 200kpa vs 30kpa in HSS
contr.mat[6,c("pressure200kpa")] <- 1
contr.mat[6,c("pressure30kpa")] <- -1
#LSS vs HSS in 30kpa
contr.mat[7,c("stressLSS","stressLSS:pressure30kpa")] <- 1
#LSS vs HSS in 200kpa
contr.mat[8,c("stressLSS","stressLSS:pressure200kpa")] <- 1
#LSS vs HSS in 1000kpa
contr.mat[9,c("stressLSS")] <- 1
library(GGally,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
install.packages('ggplot2')
install.packages('ggplot2',dependencies=TRUE)
library(ggplot2)
,.libPaths()
.libPaths()
library(ggplot2,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
library(GGally,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
install.packages('rmarkdown')
install.package('DiagrammeR')
install.packages('DiagrammeR')
library(DiagrammeR)
library(DiagrammeR,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
install.packages('DiagrammeR')
install.packages("DiagrammeR")
library(DiagrammeR)
library(dplyr,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
sessionInfo()
library(dplyr)
sessionInfo()
knitr::opts_chunk$set(echo = TRUE)
inpath="./HC_process/"
## their normalised dataset (using this for now)
aug_norm <- read.csv(file = paste0(inpath, "Aug_DC_miniprob_vsn.csv")) #6001   34
sep_norm <- read.csv(file = paste0(inpath, "Sep_DC_miniprob_vsn.csv")) #5584   34
## annotation (location of the proteins)
broad_anno <- read.csv(file = paste0(inpath, "Broad_marker_curated.csv")) #153   2
spec_anno <- read.csv(file = paste0(inpath, "Specific_marker_curated.csv")) #646   2
## making column in the same order (assuming the fraction info for each batch refers to the same fraction)
identical(colnames(aug_norm), colnames(sep_norm))
identical(sort(colnames(aug_norm)), sort(colnames(sep_norm)))
col.ord.aug_norm <- aug_norm[,order(colnames(aug_norm))][,-34]
col.ord.sep_norm <- sep_norm[,order(colnames(sep_norm))][,-34]
identical(colnames(col.ord.aug_norm), colnames(col.ord.sep_norm))
## taking the mean of replicates for downstream analysis (for now)
colnam <- unique(sub("\\_.*", "", colnames(col.ord.aug_norm)))
aug_avg <- sapply(seq(1, ncol(col.ord.aug_norm), 3), function(j) rowMeans(col.ord.aug_norm[, j+(0:2)]))
sep_avg <- sapply(seq(1, ncol(col.ord.sep_norm), 3), function(j) rowMeans(col.ord.sep_norm[, j+(0:2)]))
colnames(aug_avg) = colnames(sep_avg) <- colnam
rownames(aug_avg) <- aug_norm[,1]; rownames(sep_avg) <- sep_norm[,1]
## making sure there's no negative values
summary(as.vector(aug_avg)); summary(as.vector(sep_avg))
## adding batch info and take log to the avg values
aug_avg_log <- cbind(log(aug_avg), month=8)
sep_avg_log <- cbind(log(sep_avg), month=9)
avg_log <- rbind(aug_avg_log, sep_avg_log)
dim(avg_log)
avg,log[1,]
avg.log[1,]
avg_log[1,]
table(avg_log$month)
table(avg_log[,12])
dim(aug_norm)
dim(sep_norm)
aug_norm[1,]
sep_norm[1,]
sum(aug_norm$Protein.Group %in% sep_norm$Protein.Group
)
sum(aug_norm$Protein.Group %in% sep_norm$Protein.Group)
pca_results <- prcomp(avg_log[,-12], center = T, scale. = F)
pcs <- pca_results$x
library(ggplot2,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
library(GGally,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
dat.graph <- data.frame(pcs, Month = as.factor(avg_log[,12]))
p <- ggpairs(dat.graph,                 # Data frame
columns = 1:11,        # Columns
aes(color = Month,  # Color by group (cat. variable)
alpha = 0.5),  # Transparency
upper = list(continuous = wrap("cor", size = 1.5)),
lower = list(continuous = wrap("points", size=0.001)),
title = "PCA: Samples from Aug and Sep (normalised)")
pp <- p + theme(axis.text = element_text(size = 6))
print(pp)
install.packages('progress')
library(ggplot2,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
library(GGally,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
dat.graph <- data.frame(pcs, Month = as.factor(avg_log[,12]))
p <- ggpairs(dat.graph,                 # Data frame
columns = 1:11,        # Columns
aes(color = Month,  # Color by group (cat. variable)
alpha = 0.5),  # Transparency
upper = list(continuous = wrap("cor", size = 1.5)),
lower = list(continuous = wrap("points", size=0.001)),
title = "PCA: Samples from Aug and Sep (normalised)")
pp <- p + theme(axis.text = element_text(size = 6))
print(pp)
knitr::opts_chunk$set(echo = TRUE)
inpath="./HC_process/"
## their normalised dataset (using this for now)
aug_norm <- read.csv(file = paste0(inpath, "Aug_DC_miniprob_vsn.csv")) #6001   34
sep_norm <- read.csv(file = paste0(inpath, "Sep_DC_miniprob_vsn.csv")) #5584   34
## annotation (location of the proteins)
broad_anno <- read.csv(file = paste0(inpath, "Broad_marker_curated.csv")) #153   2
spec_anno <- read.csv(file = paste0(inpath, "Specific_marker_curated.csv")) #646   2
## making column in the same order (assuming the fraction info for each batch refers to the same fraction)
identical(colnames(aug_norm), colnames(sep_norm))
identical(sort(colnames(aug_norm)), sort(colnames(sep_norm)))
col.ord.aug_norm <- aug_norm[,order(colnames(aug_norm))][,-34]
col.ord.sep_norm <- sep_norm[,order(colnames(sep_norm))][,-34]
identical(colnames(col.ord.aug_norm), colnames(col.ord.sep_norm))
## taking the mean of replicates for downstream analysis (for now)
colnam <- unique(sub("\\_.*", "", colnames(col.ord.aug_norm)))
aug_avg <- sapply(seq(1, ncol(col.ord.aug_norm), 3), function(j) rowMeans(col.ord.aug_norm[, j+(0:2)]))
sep_avg <- sapply(seq(1, ncol(col.ord.sep_norm), 3), function(j) rowMeans(col.ord.sep_norm[, j+(0:2)]))
colnames(aug_avg) = colnames(sep_avg) <- colnam
rownames(aug_avg) <- aug_norm[,1]; rownames(sep_avg) <- sep_norm[,1]
## making sure there's no negative values
summary(as.vector(aug_avg)); summary(as.vector(sep_avg))
## adding batch info and take log to the avg values
aug_avg_log <- cbind(log(aug_avg), month=8)
sep_avg_log <- cbind(log(sep_avg), month=9)
avg_log <- rbind(aug_avg_log, sep_avg_log)
pca_results <- prcomp(avg_log[,-12], center = T, scale. = F)
pcs <- pca_results$x
library(ggplot2,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
library(GGally,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
dat.graph <- data.frame(pcs, Month = as.factor(avg_log[,12]))
p <- ggpairs(dat.graph,                 # Data frame
columns = 1:11,        # Columns
aes(color = Month,  # Color by group (cat. variable)
alpha = 0.5),  # Transparency
upper = list(continuous = wrap("cor", size = 1.5)),
lower = list(continuous = wrap("points", size=0.001)),
title = "PCA: Samples from Aug and Sep (normalised)")
pp <- p + theme(axis.text = element_text(size = 6))
print(pp)
library(uwot)
umap_results <- umap(avg_log[,-12], n_components = 11) #11585    11
colnames(umap_results) <- paste0("UMAP", 1:11)
library(GGally,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
dat.graph <- data.frame(umap_results, Month = as.factor(avg_log[,12]))
p <- ggpairs(dat.graph,                 # Data frame
columns = 1:11,        # Columns
aes(color = Month,  # Color by group (cat. variable)
alpha = 0.5),  # Transparency
upper = list(continuous = wrap("cor", size = 1.5)),
lower = list(continuous = wrap("points", size=0.001)),
title = "UMAP: Samples from Aug and Sep (normalised)")
pp <- p + theme(axis.text = element_text(size = 6))
print(pp)
library(RColorBrewer,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
library(VennDiagram)
myCol <- brewer.pal(5, "Pastel2")[c(1,5)]
Aug_proteins <- rownames(aug_avg_log)
Sep_proteins <- rownames(sep_avg_log)
venn.diagram(
x = list(Aug_proteins, Sep_proteins),
category.names = c("Aug_p", "Sep_p"),
filename = 'MeasuredProteins_venn_diagramm.png',
# output=TRUE,
# Output features
imagetype="png" ,
height = 400 ,
width = 600 ,
resolution = 200,
compression = "lzw",
# Circles
lwd = 2,
lty = 'blank',
fill = myCol,
# Numbers
cex = .6,
fontface = "bold",
fontfamily = "sans",
# Set names
cat.cex = 0.6,
cat.fontface = "bold",
cat.default.pos = "outer",
# cat.pos = c(27,135),
# cat.dist = c(0.055, 0.055, 0.085, 0.085),
cat.fontfamily = "sans"
# rotation = 1
)
dat.proteins <- rownames(dat.graph)
length(dat.proteins); length(unique(dat.proteins))
## confident anno
length(c(broad_anno$Protein.Group, spec_anno$Uniprot))
length(unique(c(broad_anno$Protein.Group, spec_anno$Uniprot)))
head(broad_anno)
head(spec_anno)
protein.gp.ls <- strsplit(rownames(avg_log), ";")
# check if the proportion of proteins without annotation actually makes sense
# length(unlist(strsplit(rownames(aug_avg_log), ";"))) #7143
# length(unique(unlist(strsplit(rownames(aug_avg_log), ";")))) #5811
# length(unlist(strsplit(rownames(sep_avg_log), ";"))) #6648
# length(unique(unlist(strsplit(rownames(sep_avg_log), ";")))) #5454
# > (5811-153)/5811 #broad
# [1] 0.9736706
# > (5811-646 )/5811 #specific
# [1] 0.8888315
## broad
match.broad.ls <- (lapply(protein.gp.ls, function(x) broad_anno$Location[match(x, broad_anno$Protein.Group)]))
table(do.call(c,match.broad.ls), useNA = "always")
extr.no.na <- do.call(c, lapply(match.broad.ls, function(x) ifelse(sum(is.na(x)) != 0, FALSE, TRUE))) #w na, wo na
match.broad.len <- do.call(c,lapply(match.broad.ls, length))
match.broad.ad <- do.call(c,lapply(match.broad.ls, function(x) ifelse(length(unique(x))==1, "Agree", "Disagree")))
table(extr.no.na, avg_log[,12]) #broad
table(avg_log[extr.no.na,12], match.broad.len[extr.no.na], match.broad.ad[extr.no.na])
broad.annot <- do.call(c,lapply(match.broad.ls, function(x) ifelse(length(unique(x))==1, x[1], NA)))
## specific
match.specific.ls <- (lapply(protein.gp.ls, function(x) spec_anno$Location[match(x, spec_anno$Uniprot)]))
table(do.call(c,match.specific.ls), useNA = "always")
extr.no.na <- do.call(c, lapply(match.specific.ls, function(x) ifelse(sum(is.na(x)) != 0, FALSE, TRUE))) #w na, wo na
match.specific.len <- do.call(c,lapply(match.specific.ls, length))
match.specific.ad <- do.call(c,lapply(match.specific.ls, function(x) ifelse(length(unique(x))==1, "Agree", "Disagree")))
table(extr.no.na, avg_log[,12]) #specific
table(avg_log[extr.no.na,12], match.specific.len[extr.no.na], match.specific.ad[extr.no.na])
spec.annot <- do.call(c,lapply(match.specific.ls, function(x) ifelse(length(unique(x))==1, x[1], NA)))
## anno.df
anno.df <- data.frame(protein.gp=rownames(avg_log),
broad.annot, spec.annot)
table(anno.df$broad.annot, useNA = "always")
table(anno.df$spec.annot, useNA = "always")
table(anno.df$broad.annot, anno.df$spec.annot, useNA = "always")
tail(anno.df)
all.df <- data.frame(ID=1:nrow(anno.df), anno.df, avg_log)
anno.dat <- all.df[which(!is.na(all.df$spec.anno)),] #1310
library(dplyr,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.2")
#obtain stratified sample
set.seed(123)
strat_sample_train <- anno.dat %>%
group_by(spec.annot) %>%
sample_frac(size=0.5)
anno.dat$train_set <- 0
anno.dat$train_set[match(strat_sample_train$ID, anno.dat$ID)] <- 1
table(anno.dat$spec.annot, anno.dat$train_set); table(anno.dat$train_set); table(anno.dat$train_set, anno.dat$month)
## group anno to number (as.factor)
{
anno.dat$spec_no <- NA
no.sub <- length(unique(anno.dat$spec.annot))
label <- 0:(no.sub-1)
CT <- unique(anno.dat$spec.annot)
for(i in 1:no.sub){
anno.dat$spec_no[which(anno.dat$spec.annot == CT[i])] <- label[i]
}
}
library(xgboost)
train.lab <- anno.dat$spec_no[which(anno.dat$train_set == 1)]
xgboost_train = xgb.DMatrix(data=as.matrix(anno.dat[which(anno.dat$train_set == 1),c(5:15)]),
label=train.lab)
test.lab <- anno.dat$spec_no[which(anno.dat$train_set == 0)]
xgboost_test = xgb.DMatrix(data=as.matrix(anno.dat[which(anno.dat$train_set == 0),c(5:15)]),
label=test.lab)
t0 <- Sys.time()
# train a model using our training data
numberOfClasses <- length(unique(as.character(train.lab)))
xgb_params <- list("objective" = "multi:softprob",
"eval_metric" = "mlogloss",
"num_class" = numberOfClasses)
built.model <- xgb.train(params = xgb_params,
data = xgboost_train,
nrounds = 1500,
nthread = 6)
# summary(built.model)
t1 <- Sys.time()
dt <- difftime(t1,t0,units="secs")
cat("training: ",dt," seconds","\n",sep="")
# training: 4.978876 seconds
## prediction
t0 <- Sys.time()
pred_test <- predict(built.model, newdata = xgboost_test)
test_label <- test.lab
test_prediction <- matrix(pred_test, nrow = numberOfClasses,
ncol=length(pred_test)/numberOfClasses) %>%
t() %>%
data.frame() %>%
mutate(true = test_label + 1, #original coding 0, 1, 2   ##true
pred_MaxProb = max.col(., "last")) ##predicted
t1 <- Sys.time()
dt <- difftime(t1,t0,units="secs")
cat("prediting on testing dat: ",dt," seconds","\n",sep="")
# prediting on testing dat: 0.1420228 seconds
test_prediction$true_lab <- as.character(anno.dat$spec.annot[which(anno.dat$train_set == 0)])
lab.mt <- test_prediction[!duplicated(test_prediction$true),which(colnames(test_prediction) %in% c("true", "true_lab"))]
test_prediction$pred_lab <- NA
for(j in 1:dim(lab.mt)[1]){
test_prediction$pred_lab[which(test_prediction$pred_MaxProb == lab.mt[j,1])] <- as.character(lab.mt[j,2])
}
all.df <- data.frame(ID=1:nrow(anno.df), anno.df, avg_log)
anno.dat <- all.df[which(!is.na(all.df$spec.anno)),] #1310
library(dplyr,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.2")
all.df <- data.frame(ID=1:nrow(anno.df), anno.df, avg_log)
anno.dat <- all.df[which(!is.na(all.df$spec.anno)),] #1310
library(dplyr,lib.loc="/home/asalim/R/x86_64-pc-linux-gnu-library/4.1")
#obtain stratified sample
set.seed(123)
strat_sample_train <- anno.dat %>%
group_by(spec.annot) %>%
sample_frac(size=0.5)
anno.dat$train_set <- 0
anno.dat$train_set[match(strat_sample_train$ID, anno.dat$ID)] <- 1
table(anno.dat$spec.annot, anno.dat$train_set); table(anno.dat$train_set); table(anno.dat$train_set, anno.dat$month)
#                                    0   1
#   40s ribosome                    26  26
#   60s ribosome                    39  39
#   actin cytoskeleton               8   8
#   chromatin                        7  11
#   cytosol                        122 122
#   endoplasmic reticulum            3   3
#   endoplasmic reticulum lumen     23  23
#   endoplasmic reticulum membrane  56  56
#   endosome                        23  23
#   extracellular matrix            12  13
#   golgi apparatus                  9   9
#   intermediate filament            6   7
#   lysosome                         4   4
#   microtubule cytoskeleton         6   6
#   mitochondrial inner membrane   162 163
#   mitochondrial matrix            19  19
#   nucleolus                        5   5
#   nucleoplasm                      9   9
#   peroxisome                      12  12
#   plasma membrane                 67  68
#   proteasome                      33  33
#
#   0   1
# 651 659
#
#   8   9
# 0 342 314
# 1 314 340
## group anno to number (as.factor)
{
anno.dat$spec_no <- NA
no.sub <- length(unique(anno.dat$spec.annot))
label <- 0:(no.sub-1)
CT <- unique(anno.dat$spec.annot)
for(i in 1:no.sub){
anno.dat$spec_no[which(anno.dat$spec.annot == CT[i])] <- label[i]
}
}
library(xgboost)
train.lab <- anno.dat$spec_no[which(anno.dat$train_set == 1)]
xgboost_train = xgb.DMatrix(data=as.matrix(anno.dat[which(anno.dat$train_set == 1),c(5:15)]),
label=train.lab)
test.lab <- anno.dat$spec_no[which(anno.dat$train_set == 0)]
xgboost_test = xgb.DMatrix(data=as.matrix(anno.dat[which(anno.dat$train_set == 0),c(5:15)]),
label=test.lab)
t0 <- Sys.time()
# train a model using our training data
numberOfClasses <- length(unique(as.character(train.lab)))
xgb_params <- list("objective" = "multi:softprob",
"eval_metric" = "mlogloss",
"num_class" = numberOfClasses)
built.model <- xgb.train(params = xgb_params,
data = xgboost_train,
nrounds = 1500,
nthread = 6)
# summary(built.model)
t1 <- Sys.time()
dt <- difftime(t1,t0,units="secs")
cat("training: ",dt," seconds","\n",sep="")
# training: 4.978876 seconds
## prediction
t0 <- Sys.time()
pred_test <- predict(built.model, newdata = xgboost_test)
test_label <- test.lab
test_prediction <- matrix(pred_test, nrow = numberOfClasses,
ncol=length(pred_test)/numberOfClasses) %>%
t() %>%
data.frame() %>%
mutate(true = test_label + 1, #original coding 0, 1, 2   ##true
pred_MaxProb = max.col(., "last")) ##predicted
t1 <- Sys.time()
dt <- difftime(t1,t0,units="secs")
cat("prediting on testing dat: ",dt," seconds","\n",sep="")
# prediting on testing dat: 0.1420228 seconds
test_prediction$true_lab <- as.character(anno.dat$spec.annot[which(anno.dat$train_set == 0)])
lab.mt <- test_prediction[!duplicated(test_prediction$true),which(colnames(test_prediction) %in% c("true", "true_lab"))]
test_prediction$pred_lab <- NA
for(j in 1:dim(lab.mt)[1]){
test_prediction$pred_lab[which(test_prediction$pred_MaxProb == lab.mt[j,1])] <- as.character(lab.mt[j,2])
}
### confusion ###
# x <- table(true = test_prediction$true_lab, predict = test_prediction$pred_lab)
# outpath="/Volumes/Transcend_4T/PhD/data/subcellular/prediction/"
# write.csv(x, file = paste0(outpath, "specific_prediction.csv"))
### accuracy ###
print(sum(test_prediction$true_lab==as.character(test_prediction$pred_lab))/length(test_prediction$true_lab))
#0.7164634
dim(anno_dat)
dim(anno.dat)
anno.dat[1,]
table(anno.dat$train_set)
table(anno.dat$spec.annot[anno.dat$train_set==1])
table(anno.dat$spec.annot[anno.dat$train_set==0])
dim(test_prediction)
anno.dat[1,]
dim(avg_log)
avg_log[1,]
AusDiab_sub <- read.csv('/home/asalim/Downloads/AusDiab_sub.csv')
View(AusDiab_sub)
setwd('/home/asalim/poisRUV/Github')
setwd('/home/asalim/poisRUV/github')
devtools::create("spaNorm")
require(splines)
require(Matrix)
require(matrixStats)
require(edgeR)
require(scran)
require(SingleCellExperiment)
sessionInfo()
devtools::document()
setwd('./spaNorm')
devtools::document()
datasets = readRDS('/home/asalim/single/spatial/Davies/BenchmarkDatasets.rds')
#filter out low libsize obs (extremes)
datasets = lapply(datasets, function(x) {
x[rowSums(counts(x)) >= 1, ]
})
spe=datasets[[8]]
spe
?usethis::use_data
usethis::use_data(spe)
HumanDLPFC=spe
usethis::use_data(HumanDLPFC)
require(scater)
sessionInfo()
